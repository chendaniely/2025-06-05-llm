[
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Setup",
    "section": "",
    "text": "Clone this repository: https://github.com/chendaniely/2025-06-05-llm\n\ngit clone https://github.com/chendaniely/2025-06-05-llm.git\ngit clone git@github.com:chendaniely/2025-06-05-llm.git\n\nUse the provided requirements.txt and renv.lock file to create the virtual environments\n\nR: you can use the setup-r Makefile target\nPython: if you have uv installed (https://docs.astral.sh/uv/) you can also use the setup-python target\nThere is a convenience make setup target that combines both for you\n\n\nmake setup"
  },
  {
    "objectID": "setup.html#r-python",
    "href": "setup.html#r-python",
    "title": "Setup",
    "section": "",
    "text": "Clone this repository: https://github.com/chendaniely/2025-06-05-llm\n\ngit clone https://github.com/chendaniely/2025-06-05-llm.git\ngit clone git@github.com:chendaniely/2025-06-05-llm.git\n\nUse the provided requirements.txt and renv.lock file to create the virtual environments\n\nR: you can use the setup-r Makefile target\nPython: if you have uv installed (https://docs.astral.sh/uv/) you can also use the setup-python target\nThere is a convenience make setup target that combines both for you\n\n\nmake setup"
  },
  {
    "objectID": "setup.html#ide",
    "href": "setup.html#ide",
    "title": "Setup",
    "section": "IDE",
    "text": "IDE\nI’m using Positron: https://positron.posit.co/, but feel free to use VS Code and/or RStudio"
  },
  {
    "objectID": "setup.html#local-llm-ollama",
    "href": "setup.html#local-llm-ollama",
    "title": "Setup",
    "section": "Local LLM: Ollama",
    "text": "Local LLM: Ollama\n\nDownload Ollama: https://ollama.com/\nPick one of the many llama models on their model page from: https://ollama.com/search.\n\nUBC has a restriction on DeekSeek\nPick any random model that will fit on your computer\nYou can pick multiple models if you’d like, we will compare results during workshop.\nHere are a few example models with their download sizes you can try:\n\n\n\n\n\nModel\nDownload Size\nURL\nInstall Command\n\n\n\n\nqwen3:0.6b\n523MB\nhttps://ollama.com/library/qwen3\nollama run qwen3:0.6b\n\n\nqwen\n5.2GB\n-\nollama run qwen3\n\n\nPhi 4 mini\n3.2GB\nhttps://ollama.com/library/phi4-reasoning\nollama run phi4-mini-reasoning\n\n\ndevstral\n14GB\nhttps://ollama.com/library/devstral\nollama run devstral\n\n\nllama4\n67GB\nhttps://ollama.com/library/llama4\nollama run llama4\n\n\nllama4:128x17b\n245GB\n-\nollama run llama4:128x17b"
  },
  {
    "objectID": "setup.html#optional-chat-provider-with-api",
    "href": "setup.html#optional-chat-provider-with-api",
    "title": "Setup",
    "section": "(Optional): Chat provider with API",
    "text": "(Optional): Chat provider with API\n\nClaude\n\nSign up at https://console.anthropic.com.\nLoad up enough credit so you won’t be sad if something goes wrong.\nCreate a key at https://console.anthropic.com/settings/keys\n\n\n\nGemini\n\nLog in to https://aistudio.google.com with a google account\nClick create API key & copy it to the clipboard.\n\n\n\nOpenAI"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Aden-Buie, Garrick. 2024. “Level Up with Shiny for R.” https://github.com/posit-conf-2024/level-up-shiny.\n\n\nChen, Daniel. 2025. “PyCon 2025 Booth Demos.” https://github.com/posit-dev/pycon2025.\n\n\nCheng, Joe. 2025a. “Harnessing LLMs for Data Analysis.” YouTube. https://www.youtube.com/watch?v=owDd1CJ17uQ.\n\n\n———. 2025b. “LLM Quickstart.” https://github.com/jcheng5/llm-quickstart.\n\n\nShiny. 2025. Shiny for Python Generative AI Documentation. https://shiny.posit.co/py/docs/genai-inspiration.html.\n\n\nTurner, Stephen. 2025. “The Modern r Stack for Production Ai.” The Modern R Stack for Production AI - by Stephen Turner. Paired Ends. https://blog.stephenturner.us/p/r-production-ai.\n\n\nWickham, Hadley. 2025. “Workshop LLM Hackathon.” https://github.com/hadley/workshop-llm-hackathon."
  },
  {
    "objectID": "partials/schedule.html",
    "href": "partials/schedule.html",
    "title": "Intro to LLMs",
    "section": "",
    "text": "Time\nActivity\n\n\n\n\n13:30\nWelcome!\n\n\n13:45\nIntroduction and Overview\n\n\n14:15\nbreak\n\n\n14:20\nLLM Packages: Chatlas + Elmer\n\n\n15:00\nbreak\n\n\n15:15\nDemos 1\n\n\n16:00\nbreak\n\n\n16:00\nNow you try\n\n\n16:30\nEnd"
  },
  {
    "objectID": "slides/020-anatomy.html#llm-conversations-are-http-requests",
    "href": "slides/020-anatomy.html#llm-conversations-are-http-requests",
    "title": "Anatomy of a Conversation",
    "section": "LLM Conversations are HTTP Requests",
    "text": "LLM Conversations are HTTP Requests\n\nEach interaction is a separate HTTP API request\nThe API server is entirely stateless (despite conversations being inherently stateful!)"
  },
  {
    "objectID": "slides/020-anatomy.html#example-conversation",
    "href": "slides/020-anatomy.html#example-conversation",
    "title": "Anatomy of a Conversation",
    "section": "Example Conversation",
    "text": "Example Conversation\n\n“What’s the capital of the moon?”\n\n\n\"There isn't one.\"\n\n\n\n“Are you sure?”\n\n\n\n\"Yes, I am sure.\""
  },
  {
    "objectID": "slides/020-anatomy.html#example-request",
    "href": "slides/020-anatomy.html#example-request",
    "title": "Anatomy of a Conversation",
    "section": "Example Request",
    "text": "Example Request\ncurl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"gpt-4.1\",\n    \"messages\": [\n        {\"role\": \"system\", \"content\": \"You are a terse assistant.\"},\n        {\"role\": \"user\", \"content\": \"What is the capital of the moon?\"}\n    ]\n}'\n\nSystem prompt: behind-the-scenes instructions and information for the model\nUser prompt: a question or statement for the model to respond to"
  },
  {
    "objectID": "slides/020-anatomy.html#example-response-abridged",
    "href": "slides/020-anatomy.html#example-response-abridged",
    "title": "Anatomy of a Conversation",
    "section": "Example Response (abridged)",
    "text": "Example Response (abridged)\n{\n  \"choices\": [{\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\": \"The moon does not have a capital. It is not inhabited or governed.\",\n    },\n    \"finish_reason\": \"stop\"\n  }],\n  \"usage\": {\n    \"prompt_tokens\": 9,\n    \"completion_tokens\": 12,\n    \"total_tokens\": 21,\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\": 0\n    }\n  }\n}"
  },
  {
    "objectID": "slides/020-anatomy.html#example-request-1",
    "href": "slides/020-anatomy.html#example-request-1",
    "title": "Anatomy of a Conversation",
    "section": "Example Request",
    "text": "Example Request\ncurl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"gpt-4.1\",\n    \"messages\": [\n      {\"role\": \"system\", \"content\": \"You are a terse assistant.\"},\n      {\"role\": \"user\", \"content\": \"What is the capital of the moon?\"},\n      {\"role\": \"assistant\", \"content\": \"The moon does not have a capital. It is not inhabited or governed.\"},\n      {\"role\": \"user\", \"content\": \"Are you sure?\"}\n    ]\n}'"
  },
  {
    "objectID": "slides/020-anatomy.html#example-response-abridged-1",
    "href": "slides/020-anatomy.html#example-response-abridged-1",
    "title": "Anatomy of a Conversation",
    "section": "Example Response (abridged)",
    "text": "Example Response (abridged)\n{\n  \"choices\": [{\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\": \"Yes, I am sure. The moon has no capital or formal governance.\"\n    },\n    \"finish_reason\": \"stop\"\n  }],\n  \"usage\": {\n    \"prompt_tokens\": 52,\n    \"completion_tokens\": 15,\n    \"total_tokens\": 67,\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\": 0\n    }\n  }\n}"
  },
  {
    "objectID": "slides/020-anatomy.html#tokens",
    "href": "slides/020-anatomy.html#tokens",
    "title": "Anatomy of a Conversation",
    "section": "Tokens",
    "text": "Tokens\n\nFundamental units of information for LLMs\nWords, parts of words, or individual characters\n\n“hello” → 1 token\n“unconventional” → 3 tokens: un|con|ventional\n4K video frame at full res → 6885 tokens\n\nExample with OpenAI Tokenizer\n\nhttps://platform.openai.com/tokenizer\n\nImportant for:\n\nModel input/output limits\nAPI pricing is usually by token\n\nhttps://gptforwork.com/tools/openai-chatgpt-api-pricing-calculator"
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "Overview",
    "section": "",
    "text": "Time\nActivity\n\n\n\n\n13:30\nWelcome!\n\n\n13:45\nIntroduction and Overview\n\n\n14:15\nbreak\n\n\n14:20\nLLM Packages: Chatlas + Elmer\n\n\n15:00\nbreak\n\n\n15:15\nDemos 1\n\n\n16:00\nbreak\n\n\n16:00\nNow you try\n\n\n16:30\nEnd",
    "crumbs": [
      "Home",
      "Overview"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Intro to LLMs",
    "section": "",
    "text": "Me sharing my experiences with LLMs and what I know so far from participating in an LLM hackathon."
  }
]