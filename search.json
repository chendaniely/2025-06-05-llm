[
  {
    "objectID": "slides/020-anatomy.html#llm-conversations-are-http-requests",
    "href": "slides/020-anatomy.html#llm-conversations-are-http-requests",
    "title": "Anatomy of a Conversation",
    "section": "LLM Conversations are HTTP Requests",
    "text": "LLM Conversations are HTTP Requests\n\nEach interaction is a separate HTTP API request\nThe API server is entirely stateless (despite conversations being inherently stateful!)"
  },
  {
    "objectID": "slides/020-anatomy.html#example-conversation",
    "href": "slides/020-anatomy.html#example-conversation",
    "title": "Anatomy of a Conversation",
    "section": "Example Conversation",
    "text": "Example Conversation\n\n“What’s the capital of the moon?”\n\n\n\"There isn't one.\"\n\n\n\n“Are you sure?”\n\n\n\n\"Yes, I am sure.\""
  },
  {
    "objectID": "slides/020-anatomy.html#example-request",
    "href": "slides/020-anatomy.html#example-request",
    "title": "Anatomy of a Conversation",
    "section": "Example Request",
    "text": "Example Request\ncurl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"gpt-4.1\",\n    \"messages\": [\n        {\"role\": \"system\", \"content\": \"You are a terse assistant.\"},\n        {\"role\": \"user\", \"content\": \"What is the capital of the moon?\"}\n    ]\n}'\n\nModel: model used\nSystem prompt: behind-the-scenes instructions and information for the model\nUser prompt: a question or statement for the model to respond to"
  },
  {
    "objectID": "slides/020-anatomy.html#example-response",
    "href": "slides/020-anatomy.html#example-response",
    "title": "Anatomy of a Conversation",
    "section": "Example Response",
    "text": "Example Response\nAbridged response:\n{\n  \"choices\": [{\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\": \"The moon does not have a capital. It is not inhabited or governed.\",\n    },\n    \"finish_reason\": \"stop\"\n  }],\n  \"usage\": {\n    \"prompt_tokens\": 9,\n    \"completion_tokens\": 12,\n    \"total_tokens\": 21,\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\": 0\n    }\n  }\n}\n\nAssistant: Response from model\nWhy did the model stop responding\nTokens: “words” used in the input and output"
  },
  {
    "objectID": "slides/020-anatomy.html#example-followup-request",
    "href": "slides/020-anatomy.html#example-followup-request",
    "title": "Anatomy of a Conversation",
    "section": "Example Followup Request",
    "text": "Example Followup Request\ncurl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"gpt-4.1\",\n    \"messages\": [\n      {\"role\": \"system\", \"content\": \"You are a terse assistant.\"},\n      {\"role\": \"user\", \"content\": \"What is the capital of the moon?\"},\n      {\"role\": \"assistant\", \"content\": \"The moon does not have a capital. It is not inhabited or governed.\"},\n      {\"role\": \"user\", \"content\": \"Are you sure?\"}\n    ]\n}'\n\nThe entire history is re-passed into the request"
  },
  {
    "objectID": "slides/020-anatomy.html#example-followup-response",
    "href": "slides/020-anatomy.html#example-followup-response",
    "title": "Anatomy of a Conversation",
    "section": "Example Followup Response",
    "text": "Example Followup Response\nAbridged Response:\n{\n  \"choices\": [{\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\": \"Yes, I am sure. The moon has no capital or formal governance.\"\n    },\n    \"finish_reason\": \"stop\"\n  }],\n  \"usage\": {\n    \"prompt_tokens\": 52,\n    \"completion_tokens\": 15,\n    \"total_tokens\": 67,\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\": 0\n    }\n  }\n}\n\nPrevious usage:\n  \"usage\": {\n    \"prompt_tokens\": 9,\n    \"completion_tokens\": 12,\n    \"total_tokens\": 21,"
  },
  {
    "objectID": "slides/020-anatomy.html#tokens",
    "href": "slides/020-anatomy.html#tokens",
    "title": "Anatomy of a Conversation",
    "section": "Tokens",
    "text": "Tokens\n\nFundamental units of information for LLMs\nWords, parts of words, or individual characters\nImportant for:\n\nModel input/output limits\nAPI pricing is usually by token\n\nhttps://gptforwork.com/tools/openai-chatgpt-api-pricing-calculator\n\n\n\nTry it yourself:\n\nhttps://tiktokenizer.vercel.app/\nhttps://platform.openai.com/tokenizer"
  },
  {
    "objectID": "slides/020-anatomy.html#token-example",
    "href": "slides/020-anatomy.html#token-example",
    "title": "Anatomy of a Conversation",
    "section": "Token example",
    "text": "Token example\nCommon words represented with a single number:\n\nWhat is the capital of the moon?\n4827, 382, 290, 9029, 328, 290, 28479, 30\n8 tokens total (including punctuation)\n\n\nOther words may require multiple numbers\n\ncounterrevolutionary\ncounter, re, volution, ary\n32128, 264, 9477, 815\n4 tokens total"
  },
  {
    "objectID": "slides/020-anatomy.html#token-pricing-anthropic",
    "href": "slides/020-anatomy.html#token-pricing-anthropic",
    "title": "Anatomy of a Conversation",
    "section": "Token pricing (Anthropic)",
    "text": "Token pricing (Anthropic)\nhttps://www.anthropic.com/pricing -&gt; API tab\n\n\n\n\nClaude Sonnet 4\n\nInput: $3 / million tokens\nOutput: $15 / million tokens\nContext window: 200k"
  },
  {
    "objectID": "slides/020-anatomy.html#context-window",
    "href": "slides/020-anatomy.html#context-window",
    "title": "Anatomy of a Conversation",
    "section": "Context window",
    "text": "Context window\n\nDetermines how much input can be incorporated into each output\nHow much of the current history the agent has in the response\n\nFor Claude Sonnet:\n\n200k token context window\n150,000 words / 300 - 600 pages / 1.5 - 2 novels\n“Gödel, Escher, Bach” ~ 67,755 words"
  },
  {
    "objectID": "slides/020-anatomy.html#context-window---chat-history",
    "href": "slides/020-anatomy.html#context-window---chat-history",
    "title": "Anatomy of a Conversation",
    "section": "Context window - chat history",
    "text": "Context window - chat history\n200k tokens seems like a lot of context…\n\n… but the entire chat is passed along each chat iteration\n{\"role\": \"system\", \"content\": \"You are a terse assistant.\"},\n{\"role\": \"user\", \"content\": \"What is the capital of the moon?\"},\n{\"role\": \"assistant\", \"content\": \"The moon does not have a capital. It is not inhabited or governed.\"},\n{\"role\": \"user\", \"content\": \"Are you sure?\"},\n{\"role\": \"assistant\", \"content\": \"Yes, I am sure. The moon has no capital or formal governance.\"}"
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Setup",
    "section": "",
    "text": "Clone this repository: https://github.com/chendaniely/2025-06-05-llm\n\ngit clone https://github.com/chendaniely/2025-06-05-llm.git\ngit clone git@github.com:chendaniely/2025-06-05-llm.git\n\nUse the provided requirements.txt and renv.lock file to create the virtual environments\n\nR: you can use the setup-r Makefile target\nPython: if you have uv installed (https://docs.astral.sh/uv/) you can also use the setup-python target\nThere is a convenience make setup target that combines both for you\n\n\nmake setup"
  },
  {
    "objectID": "setup.html#r-python",
    "href": "setup.html#r-python",
    "title": "Setup",
    "section": "",
    "text": "Clone this repository: https://github.com/chendaniely/2025-06-05-llm\n\ngit clone https://github.com/chendaniely/2025-06-05-llm.git\ngit clone git@github.com:chendaniely/2025-06-05-llm.git\n\nUse the provided requirements.txt and renv.lock file to create the virtual environments\n\nR: you can use the setup-r Makefile target\nPython: if you have uv installed (https://docs.astral.sh/uv/) you can also use the setup-python target\nThere is a convenience make setup target that combines both for you\n\n\nmake setup"
  },
  {
    "objectID": "setup.html#ide",
    "href": "setup.html#ide",
    "title": "Setup",
    "section": "IDE",
    "text": "IDE\nI’m using Positron: https://positron.posit.co/, but feel free to use VS Code and/or RStudio"
  },
  {
    "objectID": "setup.html#local-llm-ollama",
    "href": "setup.html#local-llm-ollama",
    "title": "Setup",
    "section": "Local LLM: Ollama",
    "text": "Local LLM: Ollama\n\nDownload Ollama: https://ollama.com/\nPick one of the many llama models on their model page from: https://ollama.com/search.\n\nUBC has a restriction on DeekSeek\nPick any random model that will fit on your computer\nYou can pick multiple models if you’d like, we will compare results during workshop.\nHere are a few example models with their download sizes you can try:\n\n\n\n\n\nModel\nDownload Size\nURL\nInstall Command\n\n\n\n\nqwen3:0.6b\n523MB\nhttps://ollama.com/library/qwen3\nollama run qwen3:0.6b\n\n\nqwen\n5.2GB\n-\nollama run qwen3\n\n\nPhi 4 mini\n3.2GB\nhttps://ollama.com/library/phi4-reasoning\nollama run phi4-mini-reasoning\n\n\ndevstral\n14GB\nhttps://ollama.com/library/devstral\nollama run devstral\n\n\nllama4\n67GB\nhttps://ollama.com/library/llama4\nollama run llama4\n\n\nllama4:128x17b\n245GB\n-\nollama run llama4:128x17b"
  },
  {
    "objectID": "setup.html#optional-chat-provider-with-api",
    "href": "setup.html#optional-chat-provider-with-api",
    "title": "Setup",
    "section": "(Optional): Chat provider with API",
    "text": "(Optional): Chat provider with API\nIf you pay for Claude, OpenAI, etc access with their web/desktop application, this is a separate purchase for the API key. Depending on your usage, you may even find that paying for the API key could be cheaper!\n\nAnthropic Claude\n\nSign up at https://console.anthropic.com.\nLoad up enough credit so you won’t be sad if something goes wrong.\nCreate a key at https://console.anthropic.com/settings/keys\n\n\n\nGoogle Gemini\n\nLog in to https://aistudio.google.com with a google account\nClick create API key & copy it to the clipboard.\n\n\n\nOpenAI ChatGPT"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Intro to LLMs",
    "section": "",
    "text": "Me sharing my experiences with LLMs and what I know so far from participating in an LLM hackathon.\n\n\n\n\nTime\nActivity\n\n\n\n\n13:30\nWelcome!\n\n\n13:45\nIntroduction and overview\n\n\n13:45\nAnatomy of a conversation\n\n\n14:20\nbreak\n\n\n14:30\nLLM Packages: Chatlas + Elmer\n\n\n15:20\nbreak\n\n\n15:30\nDemos 1\n\n\n16:00\nbreak / Finished\n\n\n16:00\nNow you try\n\n\n16:30\nEnd"
  },
  {
    "objectID": "010-welcome.html",
    "href": "010-welcome.html",
    "title": "Welcome",
    "section": "",
    "text": "View slides in full screen",
    "crumbs": [
      "Home",
      "Welcome"
    ]
  },
  {
    "objectID": "020-anatomy.html",
    "href": "020-anatomy.html",
    "title": "Anatomy of a conversation",
    "section": "",
    "text": "View slides in full screen",
    "crumbs": [
      "Home",
      "Anatomy of a conversation"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Aden-Buie, Garrick. 2024. “Level Up with Shiny for R.” https://github.com/posit-conf-2024/level-up-shiny.\n\n\nChen, Daniel. 2025. “PyCon 2025 Booth Demos.” https://github.com/posit-dev/pycon2025.\n\n\nCheng, Joe. 2025a. “Harnessing LLMs for Data Analysis.” YouTube. https://www.youtube.com/watch?v=owDd1CJ17uQ.\n\n\n———. 2025b. “LLM Quickstart.” https://github.com/jcheng5/llm-quickstart.\n\n\nShiny. 2025. Shiny for Python Generative AI Documentation. https://shiny.posit.co/py/docs/genai-inspiration.html.\n\n\nTurner, Stephen. 2025. “The Modern r Stack for Production Ai.” The Modern R Stack for Production AI - by Stephen Turner. Paired Ends. https://blog.stephenturner.us/p/r-production-ai.\n\n\nWickham, Hadley. 2025. “Workshop LLM Hackathon.” https://github.com/hadley/workshop-llm-hackathon."
  },
  {
    "objectID": "slides/010-welcome.html#install-setup",
    "href": "slides/010-welcome.html#install-setup",
    "title": "Welcome",
    "section": "Install + Setup",
    "text": "Install + Setup\nTake a look at the workshop website and go through the setup instructions: https://github.com/chendaniely/2025-06-05-llm\nUrl is at the bottom of all the slides.\n\nClone this repo\nInstall your R + Python packages\nDownload at least one of the Ollama models, I provided a few to pick from. Feel free to pick any other one.\n(Optional) use the .env.template file to provide your API key into .env\n\n\n\n\n\n\n\nNote\n\n\nIf you pay for Claude, OpenAI, etc access with their web/desktop application, this is a separate purchase for the API key. Depending on your usage, you may even find that paying for the API key could be cheaper!"
  },
  {
    "objectID": "slides/010-welcome.html#passing-along-what-i-learned",
    "href": "slides/010-welcome.html#passing-along-what-i-learned",
    "title": "Welcome",
    "section": "Passing along what I learned",
    "text": "Passing along what I learned\n\nJoe will do a better job than I can, but I can demo you code today.\nhttps://www.youtube.com/watch?v=owDd1CJ17uQ"
  },
  {
    "objectID": "slides/010-welcome.html#poll-experience-with-llms",
    "href": "slides/010-welcome.html#poll-experience-with-llms",
    "title": "Welcome",
    "section": "Poll: Experience with LLMs",
    "text": "Poll: Experience with LLMs\n\nUsed an LLM before (ChatGPT/Claude/Ollama desktop/web application)?\nUsed it for a homework assignment?\nMDS: Using for capstone?\nTasks outside of school work?\nSkeptical about LLMs/AI (1-2 out of 5)? Why?\nNeutral about LLMs/AI (3 out of 5)? Why?\nEnthusiastic about LLMs/AI (4-5 out of 5)? Why?"
  },
  {
    "objectID": "slides/010-welcome.html#today",
    "href": "slides/010-welcome.html#today",
    "title": "Welcome",
    "section": "Today",
    "text": "Today\n\nMDS: taught you how things work behind the scenes (transformers!)\nToday, we will treat LLMs as black boxes\nPractical introduction\nGet some hands on practice to demystify using them\n\nMDS: Maybe you can throw in something extra for the end of your capstone projects?"
  },
  {
    "objectID": "slides/010-welcome.html#goal",
    "href": "slides/010-welcome.html#goal",
    "title": "Welcome",
    "section": "Goal",
    "text": "Goal\nQuick Start course on LLMs. You will leave having used a Chat API.\n\nMDS: if you made something cool from what you learned today, share it in #llm-workshop-hackathon\n\nDoesn’t have to be “successful”\nWe’re just here trying to make cool things\nShare so we can learn about the limitations\n\nDSCI 100: We can always chat during office hours"
  },
  {
    "objectID": "slides/010-welcome.html#security",
    "href": "slides/010-welcome.html#security",
    "title": "Welcome",
    "section": "Security",
    "text": "Security\n\nDO NOT send proprietary code or data to any LLM, unless you are sure IT policies allow it\nLocal models (e.g., Ollama) typically perform worse than frontier models"
  }
]