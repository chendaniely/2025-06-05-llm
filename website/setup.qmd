---
title: Setup
---

## R + Python

1. Clone this repository: <https://github.com/chendaniely/2025-06-05-llm>
```bash
git clone https://github.com/chendaniely/2025-06-05-llm.git
git clone git@github.com:chendaniely/2025-06-05-llm.git
```

2. Use the provided `requirements.txt` and `renv.lock` file to create the virtual environments
    - R: you can use the `setup-r` `Makefile` target
    - Python: if you have `uv` installed (<https://docs.astral.sh/uv/>) you can also use the `setup-python` target
    - There is a convenience `make setup` target that combines both for you

```bash
make setup
```

## IDE

I'm using Positron: <https://positron.posit.co/>, but feel free to use VS Code and/or RStudio

## Local LLM: Ollama

1. Download Ollama: <https://ollama.com/>
2. Pick one of the many llama models on their model page: <https://ollama.com/search>.
    - [UBC has a restriction on DeekSeek](https://privacymatters.ubc.ca/i-want/safe-deepseek-ubc)
    - Pick any random model that will fit on your computer
    - You can pick multiple models if you'd like, we will compare results during workshop.
    - A few example models with model sizes:

| Model          | Download Size | URL                                         | Install Command                  |
| -------------- | ------------- | ------------------------------------------- | -------------------------------- |
| qwen3:0.6b     | 523MB         | <https://ollama.com/library/qwen3>          | `ollama run qwen3:0.6b`          |
| qwen           | 5.2GB         | -                                           | `ollama run qwen3`               |
| Phi 4 mini     | 3.2GB         | <https://ollama.com/library/phi4-reasoning> | `ollama run phi4-mini-reasoning` |
| devstral       | 14GB          | <https://ollama.com/library/devstral>       | `ollama run devstral`            |
| llama4         | 67GB          | <https://ollama.com/library/llama4>         | `ollama run llama4`              |
| llama4:128x17b | 245GB         | -                                           | `ollama run llama4:128x17b`      |

## (Optional): Chat provider with API

### Claude

1. Sign up at <https://console.anthropic.com>.
2. Load up enough credit so you won't be sad if something goes wrong.
3. Create a key at <https://console.anthropic.com/settings/keys>

### Gemini

1. Log in to <https://aistudio.google.com> with a google account
2. Click create API key & copy it to the clipboard.

### OpenAI
